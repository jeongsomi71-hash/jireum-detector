import streamlit as st
import requests
from bs4 import BeautifulSoup
import re
import urllib.parse

# ==========================================
# 1. ì‹œì„¸ ë¶„ì„ ì—”ì§„ (ê¸°ì¡´ ì •ë°€ ë¡œì§ ìœ ì§€)
# ==========================================
class DeepAnalysisEngine:
    @staticmethod
    def get_mobile_headers():
        return {
            "User-Agent": "Mozilla/5.0 (iPhone; CPU iPhone OS 17_0 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.0 Mobile/15E148 Safari/604.1",
            "Accept-Language": "ko-KR,ko;q=0.9",
            "Referer": "https://m.ppomppu.co.kr/"
        }

    @staticmethod
    def search_all_sites(product_name):
        sites = {
            "ppomppu": f"https://m.ppomppu.co.kr/new/bbs_list.php?id=ppomppu&search_type=sub_memo&keyword={urllib.parse.quote(product_name)}",
            "ruliweb": f"https://m.bbs.ruliweb.com/market/board/1020?search_type=subject&search_key={urllib.parse.quote(product_name)}",
            "clien": f"https://www.clien.net/service/search/board/jirum?sk=title&sv={urllib.parse.quote(product_name)}"
        }
        all_titles = []
        for name, url in sites.items():
            try:
                res = requests.get(url, headers=DeepAnalysisEngine.get_mobile_headers(), timeout=10)
                soup = BeautifulSoup(res.text, 'html.parser')
                if name == "ppomppu": titles = [t.get_text(strip=True) for t in soup.select('.title')]
                elif name == "ruliweb": titles = [t.get_text(strip=True) for t in soup.select('.subject_inner_text, .subject')]
                elif name == "clien": titles = [t.get_text(strip=True) for t in soup.select('.list_subject .subject_fixed')]
                all_titles.extend(titles)
            except: continue
        return all_titles

    @staticmethod
    def categorize_deal(titles):
        exclude_pattern = re.compile(r'ì¤‘ê³ |ë¯¼íŒƒ|ë¦¬í¼|Sê¸‰|Aê¸‰|Bê¸‰|ì‚¬ìš©ê°|ë§¤ì…|ì‚½ë‹ˆë‹¤')
        price_pattern = re.compile(r'([0-9,]{1,10})\s?(ì›|ë§Œ)')
        categorized_results = {}

        for text in titles:
            if exclude_pattern.search(text): continue
            found = price_pattern.findall(text)
            if not found: continue
            
            f_val, unit = found[0]
            num = int(f_val.replace(',', ''))
            if unit == 'ë§Œ': num *= 10000
            if num < 5000: continue 

            t_lower = text.lower()
            model = "ì¼ë°˜"
            if "ìš¸íŠ¸ë¼" in t_lower or "ultra" in t_lower: model = "ìš¸íŠ¸ë¼"
            elif "í”ŒëŸ¬ìŠ¤" in t_lower or "plus" in t_lower or "+" in t_lower: model = "í”ŒëŸ¬ìŠ¤"
            
            storage = "ìš©ëŸ‰ë¯¸ìƒ"
            if "128" in t_lower: storage = "128GB"
            elif "256" in t_lower: storage = "256GB"
            elif "512" in t_lower: storage = "512GB"
            elif "1tb" in t_lower or "1í‹°ë¼" in t_lower: storage = "1TB"
            
            opt = ""
            if "ìê¸‰ì œ" in t_lower: opt = "(ìê¸‰ì œ)"
            elif any(k in t_lower for k in ["í˜„ì™„", "ë²ˆì´", "ê¸°ë³€", "ì„±ì§€"]): opt = "(ì„±ì§€)"

            category_key = f"{model} {storage} {opt}".strip()
            if category_key not in categorized_results: categorized_results[category_key] = []
            categorized_results[category_key].append(num)

        final_data = {k: sorted(list(set(v))) for k, v in categorized_results.items()}
        return final_data

# ==========================================
# 2. UI ìŠ¤íƒ€ì¼ ë° ì™„ì „ ì´ˆê¸°í™” ë¡œì§
# ==========================================
def apply_custom_style():
    st.set_page_config(page_title="ì§€ë¦„ì‹  íŒë…ê¸° PRO", layout="centered")
    st.markdown("""
        <style>
        @import url('https://fonts.googleapis.com/css2?family=Noto+Sans+KR:wght@400;700;900&display=swap');
        .block-container { max-width: 550px !important; padding-top: 1.5rem !important; }
        html, body, [class*="css"] { font-family: 'Noto Sans KR', sans-serif; background-color: #000000 !important; color: #FFFFFF !important; }
        .unified-header { background-color: #FFFFFF; color: #000000 !important; text-align: center; font-size: 1.8rem; font-weight: 900; padding: 20px; border-radius: 12px; margin-bottom: 25px; border: 4px solid #00FF88; }
        .detail-card { border: 2px solid #00FF88; padding: 15px; border-radius: 12px; margin-bottom: 12px; background-color: #0A0A0A; }
        .tag-model { color: #00FF88; font-weight: 900; font-size: 1rem; }
        .tag-price { color: #FFFFFF; font-size: 1.3rem; font-weight: 700; float: right; }
        .tag-history { color: #888; font-size: 0.8rem; margin-top: 8px; border-top: 1px solid #333; padding-top: 5px; }
        .warning-footer { color: #FF4B4B; font-size: 0.8rem; text-align: center; margin-top: 30px; font-style: italic; }
        .stButton>button { width: 100%; border: 2px solid #00FF88; background-color: #000; color: #00FF88; font-weight: bold; }
        </style>
        """, unsafe_allow_html=True)

def full_reset():
    """ì•±ì˜ ëª¨ë“  ìƒíƒœì™€ í…ìŠ¤íŠ¸ ì…ë ¥ì„ ì´ˆê¸°í™”"""
    st.session_state.clear() # ì„¸ì…˜ ë¹„ìš°ê¸°
    st.query_params.clear() # URL íŒŒë¼ë¯¸í„° ë¹„ìš°ê¸° (ìµœì‹  ê¸°ëŠ¥)
    st.rerun() # ì•± ì¬ì‹œì‘

# ==========================================
# 3. ë©”ì¸ ì•±
# ==========================================
def main():
    apply_custom_style()
    st.markdown('<div class="unified-header">âš–ï¸ ì§€ë¦„ì‹  íŒë…ê¸° PRO</div>', unsafe_allow_html=True)

    col_t, col_r = st.columns([4, 1])
    with col_r:
        if st.button("ğŸ”„ ë¦¬ì…‹"):
            full_reset()

    # ì…ë ¥ì°½ (ë¦¬ì…‹ ì‹œ ê¹¨ë—í•˜ê²Œ ë¹„ì›Œì§)
    f_name = st.text_input("ğŸ“¦ ë¶„ì„í•  ì œí’ˆ ì‹œë¦¬ì¦ˆ", placeholder="ì˜ˆ: ê°¤ëŸ­ì‹œ S24, ì•„ì´í° 15", key="search_input")
    p_val = st.text_input("ğŸ’° ë‚˜ì˜ í™•ì¸ê°€ (ì„ íƒ)", placeholder="ìˆ«ìë§Œ ì…ë ¥", key="price_input")

    if st.button("ğŸ” ìš©ëŸ‰/ì˜µì…˜ë³„ ì •ë°€ ì‹œì„¸ ë¶„ì„"):
        if not f_name:
            st.error("â— ìƒí’ˆëª…ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        else:
            with st.spinner('ğŸ˜ï¸ 3ëŒ€ ì»¤ë®¤ë‹ˆí‹° 2ê°œë…„ ë°ì´í„°ë¥¼ ë¶„ì„ ì¤‘...'):
                raw_titles = DeepAnalysisEngine.search_all_sites(f_name)
                categorized_data = DeepAnalysisEngine.categorize_deal(raw_titles)

            if categorized_data:
                st.write("### ğŸ“Š ì •ë°€ ë¶„ë¥˜ ì‹œì„¸ ë¦¬í¬íŠ¸")
                sorted_keys = sorted(categorized_data.keys(), key=lambda x: categorized_data[x][0])
                for key in sorted_keys:
                    prices = categorized_data[key]
                    st.markdown(f'''
                    <div class="detail-card">
                        <span class="tag-model">â–£ {key}</span>
                        <span class="tag-price">{prices[0]:,}ì›</span>
                        <div class="tag-history">ìµœê·¼ ê¸°ë¡: {", ".join([f"{p:,}" for p in prices[1:4]])}ì›...</div>
                    </div>
                    ''', unsafe_allow_html=True)
                
                st.markdown('<div class="warning-footer">âš ï¸ ìµœê·¼ 1ë…„ ë‚´ ìµœì €ê°€ë¡œ ì¶”ì •ë˜ì§€ë§Œ ë¶€ì •í™•í•  ìˆ˜ ìˆì–´ìš”.</div>', unsafe_allow_html=True)
            else:
                st.warning("âš ï¸ ë°ì´í„°ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. í‚¤ì›Œë“œì— ì‰¼í‘œë¥¼ ì‚¬ìš©í•´ ë³´ì„¸ìš”.")

if __name__ == "__main__":
    main()
